---
title: "R Notebook"
output:
  html_document:
    df_print: paged
---

### _Running if libraries are missing..._
```{r message=FALSE, warning=FALSE, paged.print=FALSE}
# install.packages("Hmisc")
# install.packages("party")
# install.packages("MLmetrics")
```


# load packages
```{r message=FALSE, warning=FALSE, paged.print=FALSE}
library(tidyverse)
library(randomForest)
library(Hmisc)
library(party)
library(caret)
library(MLmetrics)
```

# Load the data
```{r}
data <- read_csv(file = "creditcard.csv") 
head(data)
```

# Describe data
```{r}
str(data)
```


# checking missing values
```{r}
nrow(data[is.na(data$Time)|is.na(data$Class),])
```

# make Class a factor
```{r}
data$Class <- factor(data$Class)
```

# splitting the data
```{r}
train <- data[1:150000, ]
test <- data[150001:284807, ] 
```


```{r}
train %>%
  select(Class) %>%
  group_by(Class) %>%
  summarise(count = n()) %>%
  glimpse
```

```{r}
test %>%
  select(Class) %>%
  group_by(Class) %>%
  summarise(count = n()) %>%
  glimpse
```
  
# build random forest model using every variable
```{r}
rfModel <- randomForest(Class ~ . , data = train)

test$predicted <- predict(rfModel, test)
```




```{r}
confusionMatrix(test$Class, test$predicted)
```


```{r}
F1_all <- F1_Score(test$Class, test$predicted)
F1_all
```


```{r}
options(repr.plot.width=5, repr.plot.height=4)
varImpPlot(rfModel,
          sort = T,
           n.var=10,
           main="Top 10 Most Important Variables")
```

# top predictive variables
```{r}
rfModelTrim1 <- randomForest(Class ~  V17, 
                            data = train)

test$predictedTrim1 <- predict(rfModelTrim1, test)
```


```{r}
F1_1 <- F1_Score(test$Class, test$predictedTrim1)
F1_1
```


# two variables
```{r}
rfModelTrim2 <- randomForest(Class ~  V17 + V12, 
                            data = train)

test$predictedTrim2 <- predict(rfModelTrim2, test)

F1_2 <- F1_Score(test$Class, test$predictedTrim2)
F1_2
```




# three variables
```{r}

rfModelTrim3 <- randomForest(Class ~  V17 + V12 + V14, 
                            data = train)

test$predictedTrim3 <- predict(rfModelTrim3, test)

F1_3 <- F1_Score(test$Class, test$predictedTrim3)
F1_3
```


# four variables
```{r}
rfModelTrim4 <- randomForest(Class ~  V17 + V12 + V14 + V10, 
                            data = train)

test$predictedTrim4 <- predict(rfModelTrim4, test)

F1_4 <- F1_Score(test$Class, test$predictedTrim4)
F1_4
```



# five variables
```{r}
rfModelTrim5 <- randomForest(Class ~  V17 + V12 + V14 + V10 + V16, 
                            data = train)

test$predictedTrim5 <- predict(rfModelTrim5, test)

F1_5 <- F1_Score(test$Class, test$predictedTrim5)
F1_5
```


# ten variables
```{r}
rfModelTrim10 <- randomForest(Class ~  V17 + V12 + V14 + V10 + V16 
                              + V11 + V9 + V4 + V18 + V26, 
                            data = train)

test$predictedTrim10 <- predict(rfModelTrim10, test)

F1_10 <- F1_Score(test$Class, test$predictedTrim10)
F1_10
```


# build dataframe of number of variables and scores
```{r}
numVariables <- c(1,2,3,4,5,10,17)
F1_Score <- c(F1_1, F1_2, F1_3, F1_4, F1_5, F1_10, F1_all)
variablePerf <- data.frame(numVariables, F1_Score)
```

# plot score performance against number of variables

```{r}
options(repr.plot.width=4, repr.plot.height=3)
ggplot(variablePerf, aes(numVariables, F1_Score)) + geom_point() + labs(x = "Number of Variables", y = "F1 Score", title = "F1 Score Performance")
```


```{r}
rf10 = randomForest(Class ~  V17 + V12 + V14 + V10 + V16 
                              + V11 + V9 + V4 + V18 + V26,  
                   ntree = 500,
                   data = train)
                   
options(repr.plot.width=6, repr.plot.height=4)
plot(rf10)
```


```{r}
options(repr.plot.width=6, repr.plot.height=4)
plot(rf10, xlim=c(0,100))
```















